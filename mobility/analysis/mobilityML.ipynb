{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Conclusion\n",
    "### 1) Best result with shallow or deep (2 hidden layers) neural network (177 inputs, relu or tanh activation functions with linear output)\n",
    "### 2) 1 or 2 hidden layers have comparable R-squared values (~0.6 test, ~0.9 train [overfitting is present]); 3 layers yields very poor performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for machine learning\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for database connection\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy import create_engine, func\n",
    "\n",
    "# import these to view table column headers & rows\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///../resources/mobility_db.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model (creates base class for automap schema)\n",
    "Base = automap_base()\n",
    "\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mobility_tbl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save references to each table\n",
    "mobility = Base.classes.mobility_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session (link) from Python to the database\n",
    "session = sessionmaker(bind=engine)()\n",
    "\n",
    "# View table column headers & rows\n",
    "mobility_table = select('*').select_from(mobility)\n",
    "mobility_result = session.execute(mobility_table).fetchall()\n",
    "print(mobility.__table__.columns.keys())\n",
    "# print(mobility_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a query to retrieve the data\n",
    "results = session.query(mobility.index,mobility.date,mobility.province,mobility.retail_and_recreation,mobility.grocery_and_pharmacy,mobility.parks,mobility.transit_stations,mobility.workplaces,mobility.residential,mobility.DailyTotals).all()\n",
    "\n",
    "# save the query results as a Pandas DataFrame and set the index\n",
    "df = pd.DataFrame(results, columns=['index','date', 'province', 'retail_and_recreation', 'grocery_and_pharmacy', 'parks', 'transit_stations', 'workplaces', 'residential', 'DailyTotals'])\n",
    "df.set_index(df['index'], inplace=True)\n",
    "\n",
    "# sort the dataframe by index\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlate mobility, provinces, date vs daily totals (of covid cases) per province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode provinces\n",
    "provEnc_df = pd.get_dummies(df['province'])\n",
    "provEnc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode dates\n",
    "dateEnc_df = pd.get_dummies(df['date'])\n",
    "dateEnc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns from df\n",
    "numFeatures_df = df[['retail_and_recreation','grocery_and_pharmacy', 'parks',\\\n",
    "                     'transit_stations', 'workplaces','residential']]\n",
    "numFeatures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join dfs into monster \"features_df\"\n",
    "features_df = numFeatures_df.join([provEnc_df, dateEnc_df], how=\"inner\")\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features(X) and target(y) sets\n",
    "X = features_df.values\n",
    "\n",
    "y = df['DailyTotals'].values\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and testing datasets\n",
    "# train 95% of data, test 5%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "\n",
    "# scale data\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Net (relu, linear): 100 Hidden Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model - shallow neural net\n",
    "number_hidden_nodes = 100\n",
    "number_input_features = 177\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(units=number_hidden_nodes, input_dim=number_input_features, activation=\"relu\"))\n",
    "nn.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "nn.summary()\n",
    "\n",
    "# compile model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# train model\n",
    "model_1 = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Plot the train and test loss function\n",
    "plt.plot(model_1.history[\"loss\"])\n",
    "plt.title(\"loss_function - 1 hidden layer\")\n",
    "plt.legend([\"loss\"])\n",
    "plt.show()\n",
    "\n",
    "y_train_pred = nn.predict(X_train_scaled)\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "\n",
    "print(r2_score(y_train, y_train_pred))\n",
    "print(r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Net (relu, linear): 354 Hidden Neurons (2X Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model - shallow neural net\n",
    "number_hidden_nodes = 354\n",
    "number_input_features = 177\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(units=number_hidden_nodes, input_dim=number_input_features, activation=\"relu\"))\n",
    "nn.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "nn.summary()\n",
    "\n",
    "# compile model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# train model\n",
    "model_2 = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Plot the train and test loss function\n",
    "plt.plot(model_2.history[\"loss\"])\n",
    "plt.title(\"loss_function - 1 hidden layer\")\n",
    "plt.legend([\"loss\"])\n",
    "plt.show()\n",
    "\n",
    "y_train_pred = nn.predict(X_train_scaled)\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "\n",
    "print(r2_score(y_train, y_train_pred))\n",
    "print(r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Net (relu, linear): 531 Hidden Neurons (3X Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model - shallow neural net\n",
    "number_hidden_nodes = 531\n",
    "number_input_features = 177\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(units=number_hidden_nodes, input_dim=number_input_features, activation=\"relu\"))\n",
    "nn.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "nn.summary()\n",
    "\n",
    "# compile model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# train model\n",
    "model_3 = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Plot the train and test loss function\n",
    "plt.plot(model_3.history[\"loss\"])\n",
    "plt.title(\"loss_function - 1 hidden layer\")\n",
    "plt.legend([\"loss\"])\n",
    "plt.show()\n",
    "\n",
    "y_train_pred = nn.predict(X_train_scaled)\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "\n",
    "print(r2_score(y_train, y_train_pred))\n",
    "print(r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Net (tanh, linear): 531 Hidden Neurons (3X Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model - shallow neural net\n",
    "number_hidden_nodes = 531\n",
    "number_input_features = 177\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(units=number_hidden_nodes, input_dim=number_input_features, activation=\"tanh\"))\n",
    "nn.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "nn.summary()\n",
    "\n",
    "# compile model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# train model\n",
    "model_3 = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Plot the train and test loss function\n",
    "plt.plot(model_3.history[\"loss\"])\n",
    "plt.title(\"loss_function - 1 hidden layer\")\n",
    "plt.legend([\"loss\"])\n",
    "plt.show()\n",
    "\n",
    "y_train_pred = nn.predict(X_train_scaled)\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "\n",
    "print(r2_score(y_train, y_train_pred))\n",
    "print(r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relu, relu, linear, 2 layers (160N, 80N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = 177\n",
    "hidden_nodes_layer1 = 160\n",
    "hidden_nodes_layer2 = 80\n",
    "\n",
    "nn = Sequential()\n",
    "# First hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Compile model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# Fit the model\n",
    "model_4 = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Plot the train and test loss function\n",
    "plt.plot(model_4.history[\"loss\"])\n",
    "plt.title(\"loss_function - 2 hidden layers\")\n",
    "plt.legend([\"loss\"])\n",
    "plt.show()\n",
    "\n",
    "y_train_pred = nn.predict(X_train_scaled)\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "\n",
    "print(r2_score(y_train, y_train_pred))\n",
    "print(r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tanh, tanh, linear, 2 layers (160N, 80N) [BEST MODEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = 177\n",
    "hidden_nodes_layer1 = 160\n",
    "hidden_nodes_layer2 = 80\n",
    "\n",
    "nn = Sequential()\n",
    "# First hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\"))\n",
    "# Second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "# Output layer\n",
    "nn.add(Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Compile model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# Fit the model\n",
    "model_5 = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Plot the train and test loss function\n",
    "plt.plot(model_5.history[\"loss\"])\n",
    "plt.title(\"loss_function - 2 hidden layers\")\n",
    "plt.legend([\"loss\"])\n",
    "plt.show()\n",
    "\n",
    "y_train_pred = nn.predict(X_train_scaled)\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "\n",
    "print(f'r2 score (train): {r2_score(y_train, y_train_pred)}')\n",
    "print(f'r2 score (test): {r2_score(y_test, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tanh, tanh, tanh, linear, 3 layers (160N, 80N, 40N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = 177\n",
    "hidden_nodes_layer1 = 160\n",
    "hidden_nodes_layer2 = 80\n",
    "hidden_nodes_layer3 = 40\n",
    "\n",
    "nn = Sequential()\n",
    "# First hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\"))\n",
    "# Second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "# Third hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "# Output layer\n",
    "nn.add(Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Compile model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# Fit the model\n",
    "model_6 = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Plot the train and test loss function\n",
    "plt.plot(model_6.history[\"loss\"])\n",
    "plt.title(\"loss_function - 3 hidden layers\")\n",
    "plt.legend([\"loss\"])\n",
    "plt.show()\n",
    "\n",
    "y_train_pred = nn.predict(X_train_scaled)\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "\n",
    "print(r2_score(y_train, y_train_pred))\n",
    "print(r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tanh, tanh, tanh, linear, 3 layers (80N, 40N, 20N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = 177\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 40\n",
    "hidden_nodes_layer3 = 20\n",
    "\n",
    "nn = Sequential()\n",
    "# First hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\"))\n",
    "# Second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "# Third hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "# Output layer\n",
    "nn.add(Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Compile model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# Fit the model\n",
    "model_7 = nn.fit(X_train_scaled, y_train, epochs=100)\n",
    "\n",
    "# Plot the train and test loss function\n",
    "plt.plot(model_7.history[\"loss\"])\n",
    "plt.title(\"loss_function - 3 hidden layers\")\n",
    "plt.legend([\"loss\"])\n",
    "plt.show()\n",
    "\n",
    "y_train_pred = nn.predict(X_train_scaled)\n",
    "y_test_pred = nn.predict(X_test_scaled)\n",
    "\n",
    "print(r2_score(y_train, y_train_pred))\n",
    "print(r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

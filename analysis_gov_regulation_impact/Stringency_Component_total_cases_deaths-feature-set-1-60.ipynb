{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from datetime import timedelta,datetime\n",
    "\n",
    "import sys\n",
    "from path import Path\n",
    "\n",
    "# import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the user-defined ml class\n",
    "\n",
    "class_path = Path(\"../classes/pmmfs_ml\")\n",
    "sys.path.append(class_path)\n",
    "from ml import ml\n",
    "\n",
    "from ml_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.read_csv(\"Resources/cleaned_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create four dataframes, one for each feature set to be explored for predicting future total cases and total deaths\n",
    "\n",
    "df = cleaned_df[['date','iso_code','population','population_density','median_age','C6_Stay at home requirements','C7_Restrictions on internal movement','C8_International travel controls','total_cases','total_deaths']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earlier EDA has shown that, out of the researched neural network configurations, the following neural \n",
    "# network configuration produces the most accurate results\n",
    "\n",
    "layers = { \n",
    "            \"number_input_features\": 0,   # number of input features will vary, value set elsewhere\n",
    "            \"n_layers\": 4, \n",
    "            \"l0\":{\"number_hidden_nodes\":18,\"activation_function\":\"relu\"},\n",
    "            \"l1\":{\"number_hidden_nodes\":9,\"activation_function\":\"relu\"},\n",
    "            \"l2\":{\"number_hidden_nodes\":4,\"activation_function\":\"relu\"},\n",
    "            \"l3\":{\"number_hidden_nodes\":1,\"activation_function\":\"linear\"}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_out = '60'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>iso_code</th>\n",
       "      <th>date_60</th>\n",
       "      <th>date_60</th>\n",
       "      <th>total_cases_60</th>\n",
       "      <th>total_deaths_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>ABW</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>ABW</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>ABW</td>\n",
       "      <td>2020-05-23</td>\n",
       "      <td>2020-05-23</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>ABW</td>\n",
       "      <td>2020-05-24</td>\n",
       "      <td>2020-05-24</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>ABW</td>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31800</th>\n",
       "      <td>2020-08-27</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31801</th>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31802</th>\n",
       "      <td>2020-08-29</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31803</th>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31804</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31805 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date iso_code     date_60     date_60  total_cases_60  \\\n",
       "0      2020-03-13      ABW  2020-05-12  2020-05-12           101.0   \n",
       "1      2020-03-20      ABW  2020-05-19  2020-05-19           101.0   \n",
       "2      2020-03-24      ABW  2020-05-23  2020-05-23           101.0   \n",
       "3      2020-03-25      ABW  2020-05-24  2020-05-24           101.0   \n",
       "4      2020-03-26      ABW  2020-05-25  2020-05-25           101.0   \n",
       "...           ...      ...         ...         ...             ...   \n",
       "31800  2020-08-27      ZWE  2020-10-26         NaN             NaN   \n",
       "31801  2020-08-28      ZWE  2020-10-27         NaN             NaN   \n",
       "31802  2020-08-29      ZWE  2020-10-28         NaN             NaN   \n",
       "31803  2020-08-30      ZWE  2020-10-29         NaN             NaN   \n",
       "31804  2020-08-31      ZWE  2020-10-30         NaN             NaN   \n",
       "\n",
       "       total_deaths_60  \n",
       "0                  3.0  \n",
       "1                  3.0  \n",
       "2                  3.0  \n",
       "3                  3.0  \n",
       "4                  3.0  \n",
       "...                ...  \n",
       "31800              NaN  \n",
       "31801              NaN  \n",
       "31802              NaN  \n",
       "31803              NaN  \n",
       "31804              NaN  \n",
       "\n",
       "[31805 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_day_df(df,days_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_cases %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%>\n",
      "\n",
      "\n",
      "Index(['date', 'iso_code', 'population', 'population_density', 'median_age',\n",
      "       'C6_Stay at home requirements', 'C7_Restrictions on internal movement',\n",
      "       'C8_International travel controls', 'total_cases', 'total_deaths',\n",
      "       'date_60', 'date_60', 'total_cases_60', 'total_deaths_60'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      " Training and testing - 60 days ahead\n",
      "\n",
      "\n",
      "target_n = total_cases_60\n",
      "\n",
      "features = ['population', 'population_density', 'median_age', 'C6_Stay at home requirements', 'C7_Restrictions on internal movement', 'C8_International travel controls', 'total_cases', 'total_deaths']\n",
      "population\n",
      "\n",
      "population_density\n",
      "\n",
      "median_age\n",
      "\n",
      "C6_Stay at home requirements\n",
      "\n",
      "C7_Restrictions on internal movement\n",
      "\n",
      "C8_International travel controls\n",
      "\n",
      "total_cases\n",
      "\n",
      "total_deaths\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 18)                162       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 378\n",
      "Trainable params: 378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.2938 - mse: 0.2938\n",
      "Epoch 2/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0746 - mse: 0.0746\n",
      "Epoch 3/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0627 - mse: 0.0627\n",
      "Epoch 4/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0520 - mse: 0.0520\n",
      "Epoch 5/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0440 - mse: 0.0440\n",
      "Epoch 6/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0376 - mse: 0.0376\n",
      "Epoch 7/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0328 - mse: 0.0328\n",
      "Epoch 8/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 9/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0249 - mse: 0.0249\n",
      "Epoch 10/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0220 - mse: 0.0220\n",
      "Epoch 11/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 12/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 13/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 14/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 15/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 16/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0152 - mse: 0.0152\n",
      "Epoch 17/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0153 - mse: 0.0153\n",
      "Epoch 18/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0137 - mse: 0.0137\n",
      "Epoch 19/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 20/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0135 - mse: 0.0135\n",
      "Epoch 21/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 22/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 23/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 24/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 25/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 26/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0114 - mse: 0.0114\n",
      "Epoch 27/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0110 - mse: 0.0110\n",
      "Epoch 28/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 29/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 30/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 31/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 32/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 33/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 34/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0102 - mse: 0.0102\n",
      "Epoch 35/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 36/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 37/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 38/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 39/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 40/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 41/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 42/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0105 - mse: 0.0105\n",
      "Epoch 43/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 44/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 45/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 46/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 47/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 48/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 49/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 50/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 51/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 52/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 53/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 54/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 55/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 56/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 57/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 58/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 59/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 60/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 61/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 62/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 63/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 64/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 65/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 66/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 68/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 69/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 70/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 71/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 72/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 73/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 74/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 75/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 76/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 77/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 78/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 79/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 80/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 81/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 82/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 83/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 84/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 85/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 86/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 87/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 88/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 89/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 90/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 91/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 92/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 93/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 94/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 95/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 96/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 97/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 98/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 99/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 100/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Training r2_score = 0.9944194661790323\n",
      "Testing  r2_score = 0.9925557809951147\n",
      "total_deaths %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%>\n",
      "\n",
      "\n",
      "Index(['date', 'iso_code', 'population', 'population_density', 'median_age',\n",
      "       'C6_Stay at home requirements', 'C7_Restrictions on internal movement',\n",
      "       'C8_International travel controls', 'total_cases', 'total_deaths',\n",
      "       'date_60', 'date_60', 'total_cases_60', 'total_deaths_60'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      " Training and testing - 60 days ahead\n",
      "\n",
      "\n",
      "target_n = total_deaths_60\n",
      "\n",
      "features = ['population', 'population_density', 'median_age', 'C6_Stay at home requirements', 'C7_Restrictions on internal movement', 'C8_International travel controls', 'total_cases', 'total_deaths']\n",
      "population\n",
      "\n",
      "population_density\n",
      "\n",
      "median_age\n",
      "\n",
      "C6_Stay at home requirements\n",
      "\n",
      "C7_Restrictions on internal movement\n",
      "\n",
      "C8_International travel controls\n",
      "\n",
      "total_cases\n",
      "\n",
      "total_deaths\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 18)                162       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 378\n",
      "Trainable params: 378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.4950 - mse: 0.4950\n",
      "Epoch 2/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.1632 - mse: 0.1632\n",
      "Epoch 3/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.1213 - mse: 0.1213\n",
      "Epoch 4/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.1004 - mse: 0.1004\n",
      "Epoch 5/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0846 - mse: 0.0846\n",
      "Epoch 6/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0788 - mse: 0.0788\n",
      "Epoch 7/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0713 - mse: 0.0713\n",
      "Epoch 8/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0652 - mse: 0.0652\n",
      "Epoch 9/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0621 - mse: 0.0621\n",
      "Epoch 10/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0575 - mse: 0.0575\n",
      "Epoch 11/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0549 - mse: 0.0549\n",
      "Epoch 12/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0526 - mse: 0.0526\n",
      "Epoch 13/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0499 - mse: 0.0499\n",
      "Epoch 14/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0470 - mse: 0.0470\n",
      "Epoch 15/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0452 - mse: 0.0452\n",
      "Epoch 16/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0422 - mse: 0.0422\n",
      "Epoch 17/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0406 - mse: 0.0406\n",
      "Epoch 18/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0400 - mse: 0.0400\n",
      "Epoch 19/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0383 - mse: 0.0383\n",
      "Epoch 20/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0367 - mse: 0.0367\n",
      "Epoch 21/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0367 - mse: 0.0367\n",
      "Epoch 22/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0361 - mse: 0.0361\n",
      "Epoch 23/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0345 - mse: 0.0345\n",
      "Epoch 24/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0337 - mse: 0.0337\n",
      "Epoch 25/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 26/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0358 - mse: 0.0358\n",
      "Epoch 27/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0308 - mse: 0.0308\n",
      "Epoch 28/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.0307 - mse: 0.0307\n",
      "Epoch 29/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0294 - mse: 0.0294\n",
      "Epoch 30/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0331 - mse: 0.0331\n",
      "Epoch 31/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0276 - mse: 0.0276\n",
      "Epoch 32/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0270 - mse: 0.0270\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 34/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0264 - mse: 0.0264\n",
      "Epoch 35/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 36/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.0255 - mse: 0.0255\n",
      "Epoch 37/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0253 - mse: 0.0253\n",
      "Epoch 38/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0246 - mse: 0.0246\n",
      "Epoch 39/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 40/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 41/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0242 - mse: 0.0242\n",
      "Epoch 42/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 43/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 44/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0225 - mse: 0.0225\n",
      "Epoch 45/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 46/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 47/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0215 - mse: 0.0215\n",
      "Epoch 48/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 49/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0210 - mse: 0.0210\n",
      "Epoch 50/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 51/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 52/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 53/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 54/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 55/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 56/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 57/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 58/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 59/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 60/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 61/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 62/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 63/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 64/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 65/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 66/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 67/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 68/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 69/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 70/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 71/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 72/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0183 - mse: 0.0183\n",
      "Epoch 73/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 74/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 75/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 76/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 77/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 78/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 79/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 80/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 81/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 82/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 83/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 84/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 85/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 86/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0173 - mse: 0.0173\n",
      "Epoch 87/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 88/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 89/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 90/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 91/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 92/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 93/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 94/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 95/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 96/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 97/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 98/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 99/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 100/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0165 - mse: 0.0165\n",
      "Training r2_score = 0.9846814977404752\n",
      "Testing  r2_score = 0.9827658679523591\n"
     ]
    }
   ],
   "source": [
    "# Regression Analysis\n",
    "\n",
    "# Initialize the list of models\n",
    "models = []\n",
    "\n",
    "# Get the features\n",
    "features = df.columns\n",
    "\n",
    "# Get the list of future days dataframes\n",
    "day_df = get_day_df(df,days_out)\n",
    "\n",
    "# For each of the targets, namely total_cases and total_deaths\n",
    "for target in [\"total_cases\",\"total_deaths\"]:\n",
    "\n",
    "    print(f\"{target} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%>\\n\\n\")\n",
    "\n",
    "    # Merge the feature dataframe with the day dataframe\n",
    "    df_n = df.merge(day_df,on=[\"date\",\"iso_code\"],how=\"left\")\n",
    "    print(df_n.columns)\n",
    "\n",
    "    # Remove the target columns from merged dataframe\n",
    "    features = [f for f in features if re.search(target_regex,f) == None]\n",
    "    features = features[2:]  # Remove date and iso_code\n",
    "\n",
    "    # Set the number of input features for the neural networks based on the current feature set\n",
    "    layers[\"number_input_features\"] = len(features)\n",
    "\n",
    "    # Create an instance of the ml class to start machine learning\n",
    "    md = ml(df=df_n,\n",
    "            feature_set=features,\n",
    "            test_size=0.05,\n",
    "            title=f\"{target} - {days_out} days out\",\n",
    "            target=target,\n",
    "            period=days_out,\n",
    "            **layers\n",
    "           )\n",
    "\n",
    "    # Train and test the machine learning mode over 100 epochs\n",
    "    md.train_test(epochs=100)\n",
    "\n",
    "    # Append the instance of the ml class into the models list\n",
    "    models.append(md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'iso_code', 'population', 'population_density', 'median_age',\n",
      "       'C6_Stay at home requirements', 'C7_Restrictions on internal movement',\n",
      "       'C8_International travel controls', 'total_cases', 'total_deaths',\n",
      "       'total_cases_60'],\n",
      "      dtype='object')\n",
      "Index(['date', 'iso_code', 'population', 'population_density', 'median_age',\n",
      "       'C6_Stay at home requirements', 'C7_Restrictions on internal movement',\n",
      "       'C8_International travel controls', 'total_cases', 'total_deaths',\n",
      "       'total_deaths_60'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for md in models:\n",
    "    df = md.get_df()\n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for md in models:\n",
    "    df = md.get_df()\n",
    "    model = md.get_model()\n",
    "    features = md.get_features()\n",
    "    X_scaler = md.get_X_scaler()\n",
    "    y_scaler = md.get_y_scaler()\n",
    "    \n",
    "    target = md.get_target() + \"_\" + md.get_period()\n",
    "    \n",
    "    iso_codes = df[\"iso_code\"].unique()\n",
    "    \n",
    "    for code in iso_codes:\n",
    "        X = df[df[\"iso_code\"] == code][features]\n",
    "        \n",
    "        X_scaled = X_scaler.transform(X)\n",
    "        y_pred_scaled = model.predict(X_scaled)\n",
    "        y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "        \n",
    "        df_ic = df[df[\"iso_code\"] == code]\n",
    "        \n",
    "        time = [str(t) for t in df_ic[\"date\"]]\n",
    "\n",
    "        x_vals = df_ic[\"date\"].values.tolist()\n",
    "        y_test = df_ic[target].values.tolist()  \n",
    "        y_pred_scaled = model.predict(X_scaled).reshape(-1,1).tolist()\n",
    "        y_pred = [y_scaler.inverse_transform(y) for y in y_pred_scaled]\n",
    "       \n",
    "        \n",
    "        df_c = pd.DataFrame({\"Time\":x_vals,\"Actual\":y_test, \"Predicted\": y_pred})\n",
    "\n",
    "        plt.figure(figsize=[25,15])\n",
    "        plt.plot(df_c[\"Time\"], df_c[\"Actual\"], c=\"Red\")\n",
    "        plt.plot(df_c[\"Time\"], df_c[\"Predicted\"], c=\"Green\")\n",
    "        \n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Actual/Predicted\")\n",
    "        \n",
    "        plt.title(md.get_title() + \"; Country: \" + code)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.legend([\"Actual\",\"Predicted\"])\n",
    "        \n",
    "        feature_str = \"\"\n",
    "        for feature in features:\n",
    "            if re.search(gr_regex,feature) != None:\n",
    "                feature_str = feature_str + \"_\" + feature[:2]\n",
    "                \n",
    "        plt.savefig(f\"Resources/graphs/AP_target-{md.get_target()}-features-{feature_str}-period-{md.get_period()}-country-{code}.png\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv2",
   "language": "python",
   "name": "mlenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
